{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ligerre/firsttime/blob/main/stopping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhNMGaXhYeVo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9wioXnvYjAZ"
      },
      "outputs": [],
      "source": [
        "class FRBS:\n",
        "    def __init__(self,f,z,beta,eta):\n",
        "        self._z = z\n",
        "        self._beta = beta\n",
        "        self._eta = eta*beta/2\n",
        "        self._f = f\n",
        "        #store gradient\n",
        "        self.past_z = self._f.F_operator(z)\n",
        "        #store average iterate\n",
        "        self._z_avg = torch.stack([torch.zeros(d,dtype=torch.double).to(device),torch.zeros(d,dtype=torch.double).to(device)])\n",
        "        self.cnt =0\n",
        "    def step(self):\n",
        "\n",
        "        #calculate current gradient\n",
        "        z_grad = self._f.F_operator(self._z)\n",
        "        #calculate increasement z_k+1 = z_k - eta/beta((1+beta)F(z_k)-F(z_k-1))\n",
        "        self._z = self._z - (self._eta/self._beta)*((1+self._beta)*z_grad-self.past_z)\n",
        "        #update past gradient\n",
        "        self.past_z = z_grad\n",
        "        #update average iteration\n",
        "        self.cnt+=1\n",
        "        self._z_avg = self._z_avg+self._z\n",
        "        #getting return values\n",
        "        average_val = self._f.eval(self._z_avg[0]/self.cnt,self._z_avg[1]/self.cnt)\n",
        "        return average_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4f8aTKtJYpa7"
      },
      "outputs": [],
      "source": [
        "class PEG:\n",
        "    def __init__(self,f,z,beta,eta):\n",
        "        self._z = z\n",
        "        self._beta = beta\n",
        "        self._eta = eta*beta\n",
        "        self._f = f\n",
        "        #store average iterate\n",
        "        self._z_avg = torch.stack([torch.zeros(d,dtype=torch.double).to(device),torch.zeros(d,dtype=torch.double).to(device)])\n",
        "        self.cnt =0\n",
        "    def step(self):\n",
        "        #taking half a step z_k_1/2 = z_k - eta/beta F(z_k)\n",
        "        z_half = self._z - (self._eta/self._beta)*self._f.F_operator(self._z)\n",
        "        #calculate increasement z_k+1 = z_k - eta F(z_k_1/2)\n",
        "        self._z = self._z - self._eta*self._f.F_operator(z_half)\n",
        "        #update average iteration\n",
        "        self.cnt+=1\n",
        "        self._z_avg = self._z_avg+self._z\n",
        "        #getting return values\n",
        "        average_val = self._f.eval(self._z_avg[0]/self.cnt,self._z_avg[1]/self.cnt)\n",
        "        return average_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yk_bSlU_YwjY"
      },
      "outputs": [],
      "source": [
        "class Bilinear:\n",
        "    def __init__(self,A,h,b):\n",
        "        self._A = A\n",
        "        self._H = 2*torch.matmul(torch.t(self._A),self._A)\n",
        "        self._h = h\n",
        "        self._b = b\n",
        "    def x_div(self,x,y):\n",
        "        return torch.matmul(self._H,x)-self._h - torch.matmul(torch.t(self._A),y)\n",
        "    def y_div(self,x,y): #negative gradient at y\n",
        "        return torch.matmul(self._A,x)-self._b\n",
        "    def F_operator(self,z):\n",
        "        return torch.stack([self.x_div(z[0],z[1]),self.y_div(z[0],z[1])])\n",
        "    def eval(self,x,y):\n",
        "        res = 0.5* torch.dot(x,torch.matmul(self._H,x))-torch.dot(x,self._h)-torch.dot(y,torch.matmul(self._A,x)-self._b)\n",
        "        return res.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v--al1_DYzCO"
      },
      "outputs": [],
      "source": [
        "def get_dict(file_name):\n",
        "    try:\n",
        "        with open(file_name,'rb') as f:\n",
        "            result = pickle.load(f)\n",
        "    except:\n",
        "        result = {}\n",
        "    return result\n",
        "def save_dict(dict,file_name):\n",
        "    with open(file_name, 'wb') as f:\n",
        "        pickle.dump(dict, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFnyw3YWY1AY"
      },
      "outputs": [],
      "source": [
        "def get_starting_vector(x_star,y_star,dis):\n",
        "    z_star = torch.cat([x_star.clone(),y_star.clone()])\n",
        "    l = torch.rand(2*d).to(device)\n",
        "    z_0= z_star + (dis/torch.linalg.vector_norm(l).item())*l\n",
        "    z_0 = torch.tensor_split(z_0,[d])\n",
        "\n",
        "    return z_0[0],z_0[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CxQx_ow3Y26G"
      },
      "outputs": [],
      "source": [
        "def run_FBRS(beta,eta):\n",
        "  res = 0\n",
        "  print(\"FBRS\",' ',beta)\n",
        "  for i in range(10):\n",
        "    x_0,y_0 = get_starting_vector(x_star,y_star,dis)\n",
        "    z_0 = torch.stack([x_0,y_0])\n",
        "    optimizer = FRBS(f,z_0,beta,eta)\n",
        "    avg = []\n",
        "    while True:\n",
        "        avg_res = optimizer.step()\n",
        "        avg.append(abs(avg_res-val))\n",
        "        if len(avg)>1000:\n",
        "            avg.pop(0)\n",
        "            if max(avg)<tol:\n",
        "                break\n",
        "    print(optimizer.cnt)\n",
        "    res +=optimizer.cnt\n",
        "  FBRS_list[(beta,eta/2)]=res/10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SV1IHAU9Y3NU"
      },
      "outputs": [],
      "source": [
        "def run_PEG(beta,eta):\n",
        "  print(\"PEG\",' ',beta)\n",
        "  res = 0\n",
        "  for i in range(10):\n",
        "    x_0,y_0 = get_starting_vector(x_star,y_star,dis)\n",
        "    z_0 = torch.stack([x_0,y_0])\n",
        "    optimizer = PEG(f,z_0,beta,eta)\n",
        "    avg = []\n",
        "    while True:\n",
        "        avg_res = optimizer.step()\n",
        "        avg.append(abs(avg_res-val))\n",
        "        if len(avg)>1000:\n",
        "            avg.pop(0)\n",
        "            if max(avg)<tol:\n",
        "                break\n",
        "    print(optimizer.cnt)\n",
        "    res +=optimizer.cnt\n",
        "\n",
        "  PEG_list[(beta,eta)]=res/10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmOA31DWY3ZH",
        "outputId": "27f7c9e0-4d40-4fc5-ac8e-a857c4ccfb24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "d = 1000\n",
        "dis = 10\n",
        "tol = 10**(-6)\n",
        "#generate vector A\n",
        "diag = np.ones(d)\n",
        "subdiag = -np.ones(d-1)\n",
        "A = (np.diag(diag)+np.diag(subdiag,1))*0.25\n",
        "A = np.fliplr(A).copy()\n",
        "A = torch.from_numpy(A).to(device)\n",
        "#generate b and h\n",
        "b = 0.25*torch.ones(d,dtype=torch.double).to(device)\n",
        "h = np.zeros(d)\n",
        "h[d-1] = 1\n",
        "h = h*0.25\n",
        "h = torch.from_numpy(h).to(device)\n",
        "#generate the true solution\n",
        "x_star=torch.tensor([i+1. for i in range(d)],dtype=torch.double).to(device)\n",
        "y_star = -0.5*torch.ones(d,dtype=torch.double).to(device)\n",
        "\n",
        "\n",
        "f=Bilinear(A,h,b)\n",
        "val=f.eval(x_star,y_star)\n",
        "\n",
        "FBRS_test = \"FBRS1000.txt\"\n",
        "PEG_test = \"PEG1000.txt\"\n",
        "\n",
        "FBRS_list = get_dict(FBRS_test)\n",
        "PEG_list = get_dict(PEG_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaRXK_0_ZVd0",
        "outputId": "5e4d8624-6242-48c1-da50-a920944b0e3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FBRS   1.0\n",
            "80257\n",
            "80215\n",
            "80217\n",
            "80224\n",
            "80207\n",
            "80206\n",
            "80281\n",
            "80207\n",
            "80188\n",
            "80219\n",
            "PEG   1.0\n",
            "60424\n",
            "60421\n",
            "60403\n",
            "60421\n",
            "60398\n",
            "60430\n",
            "60429\n",
            "60375\n",
            "60429\n",
            "60416\n",
            "FBRS   1.0\n",
            "64316\n",
            "64506\n",
            "64325\n",
            "64423\n",
            "64408\n",
            "64434\n",
            "64336\n",
            "64389\n",
            "64457\n",
            "64371\n",
            "PEG   1.0\n",
            "64376\n",
            "64377\n",
            "64403\n",
            "64389\n",
            "64393\n",
            "64368\n",
            "64375\n",
            "64390\n",
            "64371\n",
            "64385\n",
            "FBRS   0.85\n",
            "94242\n",
            "94259\n",
            "94238\n",
            "94248\n",
            "94244\n",
            "94188\n",
            "94165\n",
            "94194\n",
            "94228\n",
            "94258\n",
            "PEG   0.85\n",
            "70904\n",
            "70910\n",
            "70911\n",
            "70889\n",
            "70902\n",
            "70880\n",
            "70882\n",
            "70918\n",
            "70892\n",
            "70912\n",
            "FBRS   0.85\n",
            "75555\n",
            "75653\n",
            "75586\n",
            "75561\n",
            "75500\n",
            "75441\n",
            "75529\n",
            "75627\n",
            "75613\n",
            "75610\n",
            "PEG   0.85\n",
            "75538\n",
            "75600\n",
            "75528\n",
            "75560\n",
            "75556\n",
            "75545\n",
            "75552\n",
            "75531\n",
            "75611\n",
            "75563\n",
            "FBRS   0.75\n",
            "53835\n",
            "53842\n",
            "53827\n",
            "53830\n",
            "53849\n",
            "53797\n",
            "53826\n",
            "53816\n",
            "53806\n",
            "53851\n",
            "PEG   0.75\n",
            "53831\n",
            "53820\n",
            "53791\n",
            "53834\n",
            "53807\n",
            "53844\n",
            "53833\n",
            "53842\n",
            "53820\n",
            "53808\n",
            "FBRS   0.75\n",
            "85548\n",
            "85457\n",
            "85560\n",
            "85538\n",
            "85578\n",
            "85479\n",
            "85583\n",
            "85517\n",
            "85545\n",
            "85409\n",
            "PEG   0.75\n",
            "85478\n",
            "85526\n",
            "85558\n",
            "85458\n",
            "85493\n",
            "85543\n",
            "85505\n",
            "85537\n",
            "85489\n",
            "85543\n",
            "FBRS   0.6\n",
            "67055\n",
            "66999\n",
            "67033\n",
            "67121\n",
            "66943\n",
            "67073\n",
            "67051\n",
            "66992\n",
            "67011\n",
            "67072\n",
            "PEG   0.6\n",
            "66980\n",
            "67025\n",
            "67030\n",
            "67001\n",
            "67003\n",
            "67013\n",
            "67043\n",
            "67032\n",
            "67036\n",
            "67043\n",
            "FBRS   0.6\n",
            "106719\n",
            "106658\n",
            "106706\n",
            "106644\n",
            "106677\n",
            "106768\n",
            "106638\n",
            "106669\n",
            "106574\n",
            "106724\n",
            "PEG   0.6\n",
            "53819\n",
            "53798\n",
            "53843\n",
            "53790\n",
            "53818\n",
            "53845\n",
            "53821\n",
            "53845\n",
            "53842\n",
            "53814\n",
            "FBRS   0.5\n",
            "80194\n",
            "80233\n",
            "80212\n",
            "80232\n",
            "80245\n",
            "80287\n",
            "80258\n",
            "80268\n",
            "80293\n",
            "80245\n",
            "PEG   0.5\n",
            "80259\n",
            "80115\n",
            "80200\n",
            "80236\n",
            "80198\n",
            "80278\n",
            "80220\n",
            "80246\n",
            "80238\n",
            "80256\n",
            "FBRS   0.5\n",
            "127750\n",
            "127745\n",
            "127762\n",
            "127842\n",
            "127818\n",
            "127635\n",
            "127863\n",
            "127788\n",
            "127779\n",
            "127898\n",
            "PEG   0.5\n",
            "64379\n",
            "64373\n",
            "64422\n",
            "64343\n",
            "64415\n",
            "64380\n",
            "64430\n",
            "64442\n",
            "64421\n",
            "64404\n",
            "FBRS   0.32\n",
            "124759\n",
            "124795\n",
            "124876\n",
            "124795\n",
            "124839\n",
            "124863\n",
            "124779\n",
            "124908\n",
            "124881\n",
            "124858\n",
            "PEG   0.32\n",
            "62871\n",
            "62837\n",
            "62964\n",
            "62925\n",
            "62860\n",
            "62917\n",
            "62881\n",
            "62899\n",
            "62867\n",
            "62907\n",
            "FBRS   0.32\n",
            "199253\n",
            "198913\n",
            "199070\n",
            "199281\n",
            "199112\n",
            "199123\n",
            "199010\n",
            "198981\n",
            "198950\n",
            "199064\n",
            "PEG   0.32\n",
            "99972\n",
            "100034\n",
            "100137\n",
            "100046\n",
            "100071\n",
            "99979\n",
            "100080\n",
            "100141\n",
            "100096\n",
            "100073\n",
            "FBRS   0.25\n",
            "159440\n",
            "159457\n",
            "159513\n",
            "159489\n",
            "159412\n",
            "159468\n",
            "159495\n",
            "159462\n",
            "159490\n",
            "159293\n",
            "PEG   0.25\n",
            "80150\n",
            "80198\n",
            "80274\n",
            "80191\n",
            "80216\n",
            "80269\n",
            "80255\n",
            "80087\n",
            "80205\n",
            "80169\n",
            "FBRS   0.25\n",
            "254395\n",
            "254532\n",
            "254782\n",
            "254664\n",
            "254660\n",
            "254265\n",
            "254622\n",
            "254626\n",
            "254599\n",
            "254456\n",
            "PEG   0.25\n",
            "127855\n",
            "127756\n",
            "127914\n",
            "127816\n",
            "127673\n",
            "127778\n",
            "127810\n",
            "127937\n",
            "127717\n",
            "127759\n",
            "{(1.0, 0.4): 80222.1, (1.0, 0.25): 64396.5, (0.85, 0.4): 94226.4, (0.85, 0.25): 75567.5, (0.75, 0.4): 53827.9, (0.75, 0.25): 85521.4, (0.6, 0.4): 67035.0, (0.6, 0.25): 106677.7, (0.5, 0.4): 80246.7, (0.5, 0.25): 127788.0, (0.32, 0.4): 124835.3, (0.32, 0.25): 199075.7, (0.25, 0.4): 159451.9, (0.25, 0.25): 254560.1}\n",
            "{(1.0, 0.8): 60414.6, (1.0, 0.5): 64382.7, (0.85, 0.8): 70900.0, (0.85, 0.5): 75558.4, (0.75, 0.8): 53823.0, (0.75, 0.5): 85513.0, (0.6, 0.8): 67020.6, (0.6, 0.5): 53823.5, (0.5, 0.8): 80224.6, (0.5, 0.5): 64400.9, (0.32, 0.8): 62892.8, (0.32, 0.5): 100062.9, (0.25, 0.8): 80201.4, (0.25, 0.5): 127801.5}\n"
          ]
        }
      ],
      "source": [
        "betas = [1.0,0.85,0.75,0.6,0.5,0.32,0.25]\n",
        "etas = [0.8,0.5]\n",
        "for beta in betas:\n",
        "  for eta in etas:\n",
        "    run_FBRS(beta,eta)\n",
        "    run_PEG(beta,eta)\n",
        "print(FBRS_list)\n",
        "print(PEG_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMshKAYpmvg6"
      },
      "outputs": [],
      "source": [
        "save_dict(FBRS_list,FBRS_test)\n",
        "save_dict(PEG_list,PEG_test)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJtWGXi0ZMGE7KbEnSaHkJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}